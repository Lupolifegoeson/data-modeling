{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树\n",
    "常用的机器学习方法之一，对归一化不敏感，而且几乎没有超参数。\n",
    "## 离散型决策树\n",
    "普通的决策树，使用算法ID3或C4.5。这种决策树多用于离散型决策树，对于一个特征有s个离散值，则在该结点上产生s个分支。两种算法的不同主要时选择最优特征时，采用信息增益还是信息增益比。\n",
    "\n",
    "而CART算法则不同，它生成的是一个二叉决策树，不仅能用于离散数据，还能用于连续数据。在选择最优特征时，还要选择最优的划分点，同时其评判准则为基尼指数（离散数据）或平方误差（连续数据）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 离散型数据\n",
    "\n",
    "|不能上陆|有蹼|是否是鱼类|\n",
    "|--|--|--|\n",
    "|1|1|是|\n",
    "|1|1|是|\n",
    "|1|0|否|\n",
    "|0|1|否|\n",
    "|0|1|否|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset():\n",
    "    dataSet = [[1, 1, 'yes'],\n",
    "               [1, 1, 'yes'],\n",
    "               [1, 0, 'no'],\n",
    "               [0, 1, 'no'],\n",
    "               [0, 1, 'no']]\n",
    "    names = ['no surfacing','flippers']  # 不能上陆，有无蹼\n",
    "    return dataSet, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset, names = create_dataset()\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no surfacing', 'flippers']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 递归构建决策树\n",
    "换回一个嵌套的字典，形如：\n",
    "{'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}\n",
    "\n",
    "代码共分为部分：\n",
    "\n",
    "1. 递归终止条件\n",
    "    1. 只有一类\n",
    "    2. 没有用于分类的特征\n",
    "    3. \\*信息增益低于划分阈值\n",
    "2. 根绝最大增益选择特征\n",
    "3. 根据该特征划分数据集\n",
    "4. 左右子树进入递归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tree(dataset, names, features, tree):\n",
    "    \"\"\"return a tree dictionary\n",
    "    dataset: 数据集或数据集子集\n",
    "    names: 特征名称\n",
    "    features: 特征集合或特征子集 features = {0, 1} 表示第一列、第二列\n",
    "    tree: 决策树字典或决策子树字典\n",
    "    \"\"\"\n",
    "    classes = set(sample[-1] for sample in dataset)  # classes = {'yes', 'no'}\n",
    "    if len(classes) <=1:  # Only one class\n",
    "        tree = classes.pop()\n",
    "        return tree\n",
    "    if len(features) == 0:  # no feature\n",
    "        tree = majority_count(dataset, classes)\n",
    "        return tree\n",
    "\n",
    "    # 最佳特征及其下的左子树和右子树\n",
    "    (best_feature, best_value, another, \n",
    "     best_left, best_right) = choose_feature(dataset, features, classes)\n",
    "    best_feature_name = names[best_feature]\n",
    "    tree = {best_feature_name: {best_value: {}, another: {}}}\n",
    "    features.remove(best_feature)\n",
    "    print('current feature => ', best_feature_name)\n",
    "    \n",
    "    if best_left:\n",
    "        sub_tree = create_tree(best_left, names, features, tree[best_feature_name][best_feature])\n",
    "        tree[best_feature_name][best_value] = sub_tree\n",
    "    if best_right:\n",
    "        sub_tree = create_tree(best_right, names, features, tree[best_feature_name][another])\n",
    "        tree[best_feature_name][1 - best_value] = sub_tree\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_count(dataset, classes):\n",
    "    \"\"\"\n",
    "    返回叶子结点中样本最多的样本\n",
    "    \"\"\"\n",
    "    max_cnt = 0\n",
    "    max_c = None\n",
    "    labels = [sample[-1] for sample in dataset]\n",
    "    for c in classes:\n",
    "        cnt = labels.count(c)\n",
    "        if cnt > max_cnt:\n",
    "            max_cnt = cnt\n",
    "            max_c = c\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 划分数据集\n",
    "根据信息增益划分数据集：\n",
    "    \n",
    "    按照给定特征划分数据集（按上述特征划分数据集=> `split_dataset`）\n",
    "    选择最好的数据集划分方式（选择信息增益最大的特征=> `choose_best_feature`）\n",
    "    按照给定特征划分数据集（按上述特征划分数据集=> `split_dataset`）\n",
    "    ……"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, feature, value):\n",
    "    \"\"\"\n",
    "    Left is true. Right is false\n",
    "    \"\"\"\n",
    "    left, right = list(), list()\n",
    "    for sample in dataset:\n",
    "        if sample[feature] == value:\n",
    "            left.append(sample)\n",
    "        else:\n",
    "            right.append(sample)\n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_entropy(classes, *datasets):\n",
    "    entropy = 0.0\n",
    "    for d in datasets:\n",
    "        if d:\n",
    "            n_samples = len(d)\n",
    "            for c in classes:\n",
    "                proportion = [sample[-1] for sample in d].count(c) / float(n_samples)\n",
    "                if proportion != 0:\n",
    "                    entropy -= proportion * log(proportion, 2)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_feature(dataset, features, classes):\n",
    "    best_gain = 0.0\n",
    "    best_feature = 0\n",
    "    best_value = None\n",
    "    another = None\n",
    "    best_left, best_right = None, None\n",
    "    for f in features:\n",
    "        values = set(sample[f] for sample in dataset)\n",
    "        for value in values:\n",
    "            # split the dataset\n",
    "            left, right = split_dataset(dataset, f, value)\n",
    "            # calculate information gain\n",
    "            org_entropy = calc_entropy(classes, dataset)\n",
    "            new_entropy = calc_entropy(classes, left, right)\n",
    "            gain = org_entropy - new_entropy\n",
    "            if gain > best_gain:\n",
    "                best_gain = gain\n",
    "                best_feature = f\n",
    "                best_value = value\n",
    "                best_left, best_right = left, right\n",
    "        for value in values:\n",
    "            if value != best_value:\n",
    "                another = value\n",
    "                break\n",
    "    return best_feature, best_value, another, best_left, best_right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current feature =>  no surfacing\n",
      "current feature =>  flippers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = dict()\n",
    "dataset, names = create_dataset()\n",
    "features = set(range(len(dataset[0]) - 1))  # features = {0, 1}\n",
    "create_tree(dataset, names, features, tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 连续型决策树\n",
    "连续性决策树连续值的分类问题\n",
    "### 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_float(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    file_path = '../ensemble/sonar-all-data.txt'\n",
    "    dataset = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line:\n",
    "                sample = []\n",
    "                for item in line.split(','):\n",
    "                    item = item.strip()\n",
    "                    if is_float(item):\n",
    "                        sample.append(float(item))\n",
    "                    else:  # 字符=>类标签\n",
    "                        sample.append(item)\n",
    "                dataset.append(sample)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02, 0.0371, 0.0428, 0.0207, 0.0954, 0.0986, 0.1539, 0.1601, 0.3109, 0.2111, 0.1609, 0.1582, 0.2238, 0.0645, 0.066, 0.2273, 0.31, 0.2999, 0.5078, 0.4797, 0.5783, 0.5071, 0.4328, 0.555, 0.6711, 0.6415, 0.7104, 0.808, 0.6791, 0.3857, 0.1307, 0.2604, 0.5121, 0.7547, 0.8537, 0.8507, 0.6692, 0.6097, 0.4943, 0.2744, 0.051, 0.2834, 0.2825, 0.4256, 0.2641, 0.1386, 0.1051, 0.1343, 0.0383, 0.0324, 0.0232, 0.0027, 0.0065, 0.0159, 0.0072, 0.0167, 0.018, 0.0084, 0.009, 0.0032, 'R']\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset()\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建决策树\n",
    "选择基尼系数最大的特征和特征值，划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, feature, value):\n",
    "    left, right = [], []\n",
    "    for sample in dataset:\n",
    "        if sample[feature] < value:\n",
    "            left.append(sample)\n",
    "        else:\n",
    "            right.append(sample)\n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gini(classes, *datasets):\n",
    "    gini = 0.0\n",
    "    for d in datasets:\n",
    "        n_samples = len(d)\n",
    "        if n_samples == 0:\n",
    "            continue\n",
    "        for c in classes:\n",
    "            proportion = [sample[-1] for sample in d].count(c) / float(n_samples)\n",
    "            gini += proportion * (1 - proportion)\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_and_split(dataset, features, classes):\n",
    "    \"\"\"\n",
    "    choose the feature with largest Gini.\n",
    "    traverse all features=>traverse all values under current feature=>calculate Ginni\n",
    "    \"\"\"\n",
    "    min_gini = np.inf\n",
    "    best_f, best_v = 0, 0.0\n",
    "    best_left, best_right = None, None\n",
    "    for f in features:\n",
    "        values = set(sample[f] for sample in dataset)\n",
    "        for v in values:\n",
    "            left, right = split_dataset(dataset, f, v)\n",
    "            gini = calc_gini(classes, left, right)\n",
    "            if gini < min_gini:\n",
    "                min_gini = gini\n",
    "                best_f, best_v = f, v\n",
    "                best_left, best_right = left, right\n",
    "    return {'feature': best_f, 'value': best_v, 'left': best_left, 'right': best_right}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**可以选择特征数量**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randrange\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_features(dataset, n_features):\n",
    "    features = set()\n",
    "    while len(features) < n_features:\n",
    "        f = randrange(len(dataset[0]) - 1)\n",
    "        features.add(f)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 迭代生成决策树\n",
    "生成决策树的迭代停止的条件：\n",
    "\n",
    "- 节点中只有一类\n",
    "- 特征用尽\n",
    "- 达到最大深度限制\n",
    "- 达到最小叶子结点限制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tree(dataset, max_depth, min_size, n_features):\n",
    "    features = sub_features(dataset, n_features)\n",
    "    classes = set(sample[-1] for sample in dataset)\n",
    "    root = choose_and_split(dataset, features, classes)\n",
    "    features.remove(root['feature'])\n",
    "    create_node(root, features, max_depth, min_size, 1)\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_class(dataset):\n",
    "    labels = [sample[-1] for sample in dataset]\n",
    "    lb = max(set(labels), key=labels.count)\n",
    "    return lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_node(node, features, max_depth, min_size, depth):\n",
    "    print('create node>>>')\n",
    "    left, right = node['left'], node['right']\n",
    "    if left:\n",
    "        classes = set(sample[-1] for sample in left)\n",
    "        # Only one class or no feauture remained\n",
    "        if (len(classes) == 1 or len(features) == 0 or \n",
    "            not features or len(left) < min_size or depth >= max_depth):\n",
    "            # return classification result\n",
    "            node['left'] = majority_class(left)\n",
    "        else:\n",
    "            node['left'] = choose_and_split(left, features, classes)\n",
    "            features.remove(node['left']['feature'])\n",
    "            create_node(node['left'], features, \n",
    "                        max_depth, min_size, depth+1)\n",
    "    if right:\n",
    "        classes = set(sample[-1] for sample in right)\n",
    "        if (len(classes) == 1 or len(features) == 0 or \n",
    "           not features or len(left) < min_size or depth >= max_depth):\n",
    "            node['right'] = majority_class(right)\n",
    "        else:\n",
    "            node['right'] = choose_and_split(right, features, classes)\n",
    "            features.remove(node['right']['feature'])\n",
    "            create_node(node['right'], features, \n",
    "                        max_depth, min_size, depth+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create node>>>\n",
      "create node>>>\n",
      "create node>>>\n",
      "create node>>>\n",
      "create node>>>\n",
      "create node>>>\n",
      "create node>>>\n",
      "create node>>>\n",
      "create node>>>\n",
      "create node>>>\n",
      "create node>>>\n",
      "create node>>>\n",
      "create node>>>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'feature': 48,\n",
       " 'left': 'R',\n",
       " 'right': {'feature': 10,\n",
       "  'left': 'R',\n",
       "  'right': {'feature': 12,\n",
       "   'left': 'R',\n",
       "   'right': {'feature': 31,\n",
       "    'left': 'R',\n",
       "    'right': {'feature': 35,\n",
       "     'left': {'feature': 38,\n",
       "      'left': {'feature': 39,\n",
       "       'left': 'R',\n",
       "       'right': {'feature': 11,\n",
       "        'left': {'feature': 15,\n",
       "         'left': {'feature': 56,\n",
       "          'left': 'R',\n",
       "          'right': {'feature': 49,\n",
       "           'left': 'R',\n",
       "           'right': {'feature': 51,\n",
       "            'left': 'R',\n",
       "            'right': {'feature': 32,\n",
       "             'left': [],\n",
       "             'right': 'M',\n",
       "             'value': 0.0477},\n",
       "            'value': 0.0013},\n",
       "           'value': 0.0044},\n",
       "          'value': 0.0009},\n",
       "         'right': 'R',\n",
       "         'value': 0.9751},\n",
       "        'right': 'R',\n",
       "        'value': 0.6552},\n",
       "       'value': 0.0227},\n",
       "      'right': 'R',\n",
       "      'value': 0.8849},\n",
       "     'right': 'R',\n",
       "     'value': 0.9922},\n",
       "    'value': 0.0877},\n",
       "   'value': 0.0616},\n",
       "  'value': 0.0523},\n",
       " 'value': 0.0098}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_tree(dataset, 15, 1, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0286, 0.0453, 0.0277, 0.0174, 0.0384, 0.099, 0.1201, 0.1833, 0.2105, 0.3039, 0.2988, 0.425, 0.6343, 0.8198, 1.0, 0.9988, 0.9508, 0.9025, 0.7234, 0.5122, 0.2074, 0.3985, 0.589, 0.2872, 0.2043, 0.5782, 0.5389, 0.375, 0.3411, 0.5067, 0.558, 0.4778, 0.3299, 0.2198, 0.1407, 0.2856, 0.3807, 0.4158, 0.4054, 0.3296, 0.2707, 0.265, 0.0723, 0.1238, 0.1192, 0.1089, 0.0623, 0.0494, 0.0264, 0.0081, 0.0104, 0.0045, 0.0014, 0.0038, 0.0013, 0.0089, 0.0057, 0.0027, 0.0051, 0.0062, 'R']\n"
     ]
    }
   ],
   "source": [
    "test_sample = dataset[5]\n",
    "print(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sample, tree):\n",
    "    if sample[tree['feature']] < tree['value']:\n",
    "        if len(tree['left']) == 1:\n",
    "            return tree['left']\n",
    "        else:\n",
    "            return predict(sample, tree['left'])\n",
    "    else:\n",
    "        if len(tree['right']) == 1:\n",
    "            return tree['right']\n",
    "        else:\n",
    "            return predict(sample, tree['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create node>>>\n",
      "create node>>>\n",
      "create node>>>\n",
      "create node>>>\n",
      "create node>>>\n",
      "create node>>>\n",
      "create node>>>\n",
      "create node>>>\n",
      "create node>>>\n",
      "create node>>>\n",
      "create node>>>\n",
      "create node>>>\n"
     ]
    }
   ],
   "source": [
    "tree = create_tree(dataset, 15, 1, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'R'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(test_sample, tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
