{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 随机森林\n",
    "随机森林分类效果（错误率）与两个因素有关：\n",
    "- 森林中任意两棵树的相关性：相关性越大，错误率越大；\n",
    "- 森林中每棵树的分类能力：每棵树的分类能力越强，这个森林的错误率越低\n",
    "\n",
    "减小特征选择个数m，树的相关性和分类能力也会相应的降低；增大m，两者也会随之增大。所以**关键问题是如何选择最优的m（或者是范围）**，这也是随机森林唯一的一个参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> bagging和boosting区别是什么？\n",
    "\n",
    "1. bagging是一种与boosting很类似的技术，所使用的多个分类器的类型（数据量和特征量）都是一致的。\n",
    "2. bagging是由不同的分类器（1.数据随机化2.特征随机化）经过训练，综合得出的出现最多分类结果；boosting是通过调整已有分类器错分的那些数据来获得新的分类器，得出目前最优的结果。\n",
    "3. bagging中的分类器权重是相等的；而boosting中的分类器加权求和，所以权重并不相等，每个权重代表的是其对应分类器在上一轮迭代中的成功度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 伪代码\n",
    "```\n",
    "采取有放回的抽样方式构造子数据集，保证不同子集之间的数量级一样（不同子集/同一子集之间的元素可以重复）\n",
    "利用子集数据来构建决策树\n",
    "预测时，将这个数据放到每个字决策树中，每个子决策树输出一个结果。\n",
    "统计子决策树的投票结果，得到最终的分类就是随机森林的输出结果。\n",
    "```\n",
    "![特征重抽样](feature-resample.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建一颗决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_float(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    file_path = '../ensemble/sonar-all-data.txt'\n",
    "    dataset = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line:\n",
    "                sample = []\n",
    "                for item in line.split(','):\n",
    "                    item = item.strip()\n",
    "                    if is_float(item):\n",
    "                        sample.append(float(item))\n",
    "                    else:  # 字符=>类标签\n",
    "                        sample.append(item)\n",
    "                dataset.append(sample)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02, 0.0371, 0.0428, 0.0207, 0.0954, 0.0986, 0.1539, 0.1601, 0.3109, 0.2111, 0.1609, 0.1582, 0.2238, 0.0645, 0.066, 0.2273, 0.31, 0.2999, 0.5078, 0.4797, 0.5783, 0.5071, 0.4328, 0.555, 0.6711, 0.6415, 0.7104, 0.808, 0.6791, 0.3857, 0.1307, 0.2604, 0.5121, 0.7547, 0.8537, 0.8507, 0.6692, 0.6097, 0.4943, 0.2744, 0.051, 0.2834, 0.2825, 0.4256, 0.2641, 0.1386, 0.1051, 0.1343, 0.0383, 0.0324, 0.0232, 0.0027, 0.0065, 0.0159, 0.0072, 0.0167, 0.018, 0.0084, 0.009, 0.0032, 'R']\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset()\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, feature, value):\n",
    "    left, right = [], []\n",
    "    for sample in dataset:\n",
    "        if sample[feature] < value:\n",
    "            left.append(sample)\n",
    "        else:\n",
    "            right.append(sample)\n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gini(classes, *datasets):\n",
    "    gini = 0.0\n",
    "    for d in datasets:\n",
    "        n_samples = len(d)\n",
    "        if n_samples == 0:\n",
    "            continue\n",
    "        for c in classes:\n",
    "            proportion = [sample[-1] for sample in d].count(c) / float(n_samples)\n",
    "            gini += proportion * (1 - proportion)\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_and_split(dataset, features, classes):\n",
    "    min_gini = np.inf\n",
    "    best_f, best_v = 0, 0.0\n",
    "    best_left, best_right = None, None\n",
    "    for f in features:\n",
    "        values = set(sample[f] for sample in dataset)\n",
    "        for v in values:\n",
    "            left, right = split_dataset(dataset, f, v)\n",
    "            gini = calc_gini(classes, left, right)\n",
    "            if gini < min_gini:\n",
    "                min_gini = gini\n",
    "                best_f, best_v = f, v\n",
    "                best_left, best_right = left, right\n",
    "    return {'feature': best_f, 'value': best_v, 'left': best_left, 'right': best_right}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**随机森林的要素之一 => 随机选择特征**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randrange\n",
    "import numpy as np\n",
    "def sub_features(dataset, n_features):\n",
    "    features = set()\n",
    "    while len(features) < n_features:\n",
    "        f = randrange(len(dataset[0]) - 1)\n",
    "        features.add(f)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tree(dataset, max_depth, min_size, n_features):\n",
    "    features = sub_features(dataset, n_features)\n",
    "    classes = set(sample[-1] for sample in dataset)\n",
    "    root = choose_and_split(dataset, features, classes)\n",
    "    features.remove(root['feature'])\n",
    "    create_node(root, features, max_depth, min_size, 1)\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_class(dataset):\n",
    "    labels = [sample[-1] for sample in dataset]\n",
    "    lb = max(set(labels), key=labels.count)\n",
    "    return lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_node(node, features, max_depth, min_size, depth):\n",
    "    left, right = node['left'], node['right']\n",
    "    # 这里的意义是，left或right可能出现为空列表[]的情况\n",
    "    # 这样就会造成预测产生TypeError\n",
    "    # 故排除这种情况\n",
    "    if not left or not right:\n",
    "        node['left'] = node['right'] = majority_class(left + right)\n",
    "        return\n",
    "    if left:\n",
    "        classes = set(sample[-1] for sample in left)\n",
    "        # Only one class or no feauture remained\n",
    "        if (len(classes) == 1 or len(features) == 0 or \n",
    "            not features or len(left) < min_size or depth >= max_depth):\n",
    "            # return classification result\n",
    "            node['left'] = majority_class(left)\n",
    "        else:\n",
    "            node['left'] = choose_and_split(left, features, classes)\n",
    "            features.remove(node['left']['feature'])\n",
    "            create_node(node['left'], features, \n",
    "                        max_depth, min_size, depth+1)\n",
    "    if right:\n",
    "        classes = set(sample[-1] for sample in right)\n",
    "        if (len(classes) == 1 or len(features) == 0 or \n",
    "           not features or len(left) < min_size or depth >= max_depth):\n",
    "            node['right'] = majority_class(right)\n",
    "        else:\n",
    "            node['right'] = choose_and_split(right, features, classes)\n",
    "            features.remove(node['right']['feature'])\n",
    "            create_node(node['right'], features, \n",
    "                        max_depth, min_size, depth+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成随机森林"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**随机森林的要素之二 => 为每棵决策树随机选择训练集**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_samples(dataset, ratio):\n",
    "    samples = []\n",
    "    n_sample = round(len(dataset) * ratio)\n",
    "    while len(samples) < n_sample:\n",
    "        index = randrange(len(dataset))\n",
    "        samples.append(dataset[index])\n",
    "    return list(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(node, sample):\n",
    "    if sample[node['feature']] < node['value']:\n",
    "        if isinstance(node['left'], dict):\n",
    "            return predict(node['left'], sample)\n",
    "        else:\n",
    "            return node['left']\n",
    "    else:\n",
    "        if isinstance(node['right'], dict):\n",
    "            return predict(node['right'], sample)\n",
    "        else:\n",
    "            return node['right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagging_predict(trees, sample):\n",
    "    predictions = [predict(tree, sample) for tree in trees]\n",
    "    return max(set(predictions), key=predictions.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(train, test, max_depth=20, min_size=1, sample_size=0.75, n_trees=10, n_features=30):\n",
    "    \"\"\"\n",
    "    Use random forest and return a prediction.\n",
    "    train: 训练数据集\n",
    "    test: 测试数据集\n",
    "    max_depth: 决策树深度限制，太深容易过拟合\n",
    "    min_size: 叶子结点大小限制\n",
    "    sample_size: 单个树的训练集随机采样的比例\n",
    "    n_trees: 决策树个数\n",
    "    n_features: 随机选择的特征的个数\n",
    "    \"\"\"\n",
    "    trees = []\n",
    "    for i in range(n_trees):\n",
    "        sub_train = sub_samples(train, sample_size)\n",
    "        tree = create_tree(sub_train, max_depth, min_size, n_features)\n",
    "        trees.append(tree)\n",
    "    predictions = [bagging_predict(trees, sample) for sample in test]\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_metric(actual, predictions):\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predictions[i]:\n",
    "            correct += 1\n",
    "    return correct / float(len(actual)) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions=>  ['M', 'R', 'R', 'M', 'M', 'M', 'M', 'R', 'R', 'R']\n",
      "labels=>  ['M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M']\n",
      "使用随机森林检测声呐信号的准确率是=> 50.0\n"
     ]
    }
   ],
   "source": [
    "train_set = dataset[:-10]\n",
    "test_set = []\n",
    "for sample in dataset[-10:]:\n",
    "    sample_copy = list(sample)\n",
    "    sample_copy[-1] = None\n",
    "    test_set.append(sample_copy)\n",
    "predictions = random_forest(train_set, test_set)\n",
    "actual_labels = [sample[-1] for sample in dataset[-10:]]\n",
    "print('predictions=> ', predictions)\n",
    "print('labels=> ', actual_labels)\n",
    "accuracy = accuracy_metric(actual_labels, predictions)\n",
    "print('使用随机森林检测声呐信号的准确率是=>', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>准确率这么低，可能是代码中有bug。但是我确实找不出来了，希望有人看到问题所在后可以告诉我=>**983910368@qq.com**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
